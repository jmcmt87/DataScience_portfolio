{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter Basic Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from google_trans_new import google_translator  # pip install google_trans_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will perform sentiment analysis on a list of tweets using just json, pandas, regex and a google translate.\n",
    "\n",
    "We have two files, one file 'tweets.txt' with all raw data in json format from tweeter, and another file 'Sentimientos.txt' with a list of words and their associated sentiment value, some have a positive value and others have a negative value, these values are supposed to give us information about the tweets general sentiments.\n",
    "\n",
    "The goal is to be able to check the sentiment value of every tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating the dictionary values with information from the file Sentimientos.txt\n",
    "\n",
    "sentiments = open(\"Sentimientos.txt\") \n",
    "values = {} \n",
    "for line in sentiments: \n",
    "    term, value = line.split(\"\\t\") \n",
    "    values[term] = int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating the data list with all the information about the tweets given in tweets.txt\n",
    "\n",
    "data = []\n",
    "with open('tweets.txt') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Withdrawing texts and ids from the tweets and putting them in a tweets list and a ids list\n",
    "\n",
    "tweets = [] \n",
    "ids = [] \n",
    "for i in range(len(data)):\n",
    "    if 'text' in data[i]:\n",
    "        tweets.append(data[i]['text'])\n",
    "        ids.append(data[i]['id'])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_translate(string):\n",
    "    '''This function translates to English any given string'''\n",
    "    translator = google_translator()\n",
    "    trans = translator.translate(string, lang_tgt = 'en')\n",
    "    return trans\n",
    "\n",
    "# This loop translates all the tweets to English into a list called translations\n",
    "\n",
    "translations = []\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    translations.append(str(google_translate(tweets[i]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning sentiment values to tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comprehension list gives every word that are present in the values list its value, and it gives a 0 value\n",
    "#to words that are not in the list:\n",
    "    \n",
    "sentiment = [\n",
    "    sum(\n",
    "        values[word] if word in values else 0 \n",
    "        for word in re.split('[^a-z]+', translation.lower()) # The comprehension lists use regex to separate \n",
    "        #words from any punctuation sign or number\n",
    "    ) \n",
    "    for translation in translations\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509748524897292288</th>\n",
       "      <td>@Brenamae_ I WHALE SLAP YOUR FIN AND TELL YOU ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509748529070616576</th>\n",
       "      <td>Metin ÅentÃ¼rk Twitterda @metinsenturk MUHTEÅEM...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509748529095774208</th>\n",
       "      <td>RT @byunghns: ğŸ˜­ I LOVE #í‹´íƒ‘ SO MUCH #ì‰½ì§€ì•Šì•„ IS GO...</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509748529104175104</th>\n",
       "      <td>que hdp maicon lo que le hizo a david luiz jaj...</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509748529107988480</th>\n",
       "      <td>ãƒ‰ãƒ©ã‚¤ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Tweet  ...  \\\n",
       "Id                                                                     ...   \n",
       "509748524897292288  @Brenamae_ I WHALE SLAP YOUR FIN AND TELL YOU ...  ...   \n",
       "509748529070616576  Metin ÅentÃ¼rk Twitterda @metinsenturk MUHTEÅEM...  ...   \n",
       "509748529095774208  RT @byunghns: ğŸ˜­ I LOVE #í‹´íƒ‘ SO MUCH #ì‰½ì§€ì•Šì•„ IS GO...  ...   \n",
       "509748529104175104  que hdp maicon lo que le hizo a david luiz jaj...  ...   \n",
       "509748529107988480             ãƒ‰ãƒ©ã‚¤ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼  ...   \n",
       "\n",
       "                   Sentiment  \n",
       "Id                            \n",
       "509748524897292288         0  \n",
       "509748529070616576         0  \n",
       "509748529095774208         6  \n",
       "509748529104175104        -4  \n",
       "509748529107988480         0  \n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the data frame:\n",
    "\n",
    "# Set pandas to display all rows\n",
    "pd.set_option('display.max_rows', None, 'display.max_columns', 2)\n",
    "\n",
    "# intialise data of lists. \n",
    "d = {'Id': ids, 'Tweet':tweets,'Translation' : translations, 'Sentiment': sentiment}\n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(d) \n",
    "\n",
    "#Setting the index to the column 'Id'\n",
    "df.set_index('Id', inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_information(index):\n",
    "    '''This function accepts the tweet id and returns the tweet, the sentiment value\n",
    "    and translation if the language of the tweet is in any language other than English'''\n",
    "    detect_result = google_translator().detect(df.Tweet.loc[index])  \n",
    "    if detect_result[1] != 'english': # If the detected language is other than English the function returns the \n",
    "        #following:\n",
    "        return print(\n",
    "        'Tweet: \\'{}\\' \\n\\nSentiment value: {}.\\n\\nTranslation: \\'{}\\'\\n\\nTranslated from {}'.format(\n",
    "        df.Tweet.loc[index], df.Sentiment.loc[index], # The function withdraws information from the pandas data \n",
    "            #frame\n",
    "        df.Translation.loc[index], detect_result[1].title() # The detect_result functions returns two outputs \n",
    "            #like this ('ja', 'japanese'), it returns the second item capitalized\n",
    "        )) \n",
    "    else:\n",
    "        return print('Tweet: \\'{}\\' \\n\\nSentiment value: {}'.format\n",
    "                     (df.Tweet.loc[index], df.Sentiment.loc[index])\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'ãƒ‰ãƒ©ã‚³ãƒ»ãƒãƒ«ãƒ•ã‚©ã‚¤ã€€ã€Œé—‡ã®å¸ç‹ãŒæ”¯é…ãªã•ã‚‹æ™‚ã€OWLã‚„NEWTãŒä½•ç§‘ç›®ãªã‚“ã¦ã€ã‚ã®äººã€ãŒæ°—ã«ãªã•ã‚‹ã‹ï¼Ÿã‚‚ã¡ã‚ã‚“ã€ãã‚“ãªã“ã¨ã¯å•é¡Œã˜ã‚ƒãªã„ãƒ»ãƒ»ãƒ»ã€ã‚ã®äººã€ã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«å¥‰ä»•ã—ã€ã©ã®ã‚ˆã†ãªçŒ®èº«ã¶ã‚Šã‚’ç¤ºã—ã¦æ¥ãŸã‹ã ã‘ãŒé‡è¦ã ã€' \n",
      "\n",
      "Sentiment value: 8.\n",
      "\n",
      "Translation: 'Draco Malfoy \"When the Dark Emperor rules, how many subjects do OWL and NEWT care about\" that person \"? Of course, that doesn't matter ... how for\" that person \"? Only what you have served and how devoted you have been is important. \" '\n",
      "\n",
      "Translated from Japanese\n"
     ]
    }
   ],
   "source": [
    "# Checking tweets:\n",
    "\n",
    "tweet_information(509748529074417666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'Ø§Ù„Ù„Ù‡ Ø£ÙƒØ¨Ø± Ø§Ù„Ù„Ù‡ Ø£ÙƒØ¨Ø± Ø§Ù„Ù„Ù‡ Ø£ÙƒØ¨Ø±, Ù„Ø§ Ø¥Ù„Ù‡ Ø¥Ù„Ø§ Ø§Ù„Ù„Ù‡, Ø§Ù„Ù„Ù‡ Ø£ÙƒØ¨Ø± Ø§Ù„Ù„Ù‡ Ø§ÙƒØ¨Ø± ÙˆÙ„Ù„Ù‡ Ø§Ù„Ø­Ù…Ø¯ http://t.co/M454OhQpYY' \n",
      "\n",
      "Sentiment value: 25.\n",
      "\n",
      "Translation: 'God is great God is great God is great, there is no god but God, God is great God is great, praise be to God http://t.co/M454OhQpYY '\n",
      "\n",
      "Translated from Arabic\n"
     ]
    }
   ],
   "source": [
    "tweet_information(509748529104191488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'RT @maamsalcatraz: Cette gomme la plus grosse arnaque du siÃ¨cle elle Ã©tait sensÃ© gommÃ© ls stylo ,mais elle dÃ©chirer la feuille cet pute httâ€¦' \n",
      "\n",
      "Sentiment value: -7.\n",
      "\n",
      "Translation: 'RT @maamsalcatraz: This eraser the biggest scam of the century she was supposed to erase the pen, but she tear the sheet this bitch httâ€¦ '\n",
      "\n",
      "Translated from French\n"
     ]
    }
   ],
   "source": [
    "tweet_information(509748537471827968)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
